{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfa8087c",
   "metadata": {},
   "source": [
    "# Data Exploration: BluePrint and Reddit Moderator Perceptions\n",
    "\n",
    "This notebook explores the two datasets used for simulating social media moderation policies:\n",
    "1. BluePrint: Human-AI social interactions dataset\n",
    "2. Reddit Moderator Perceptions: Moderator interpretations of toxic content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c034d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1r1hp4v2c",
   "metadata": {},
   "source": [
    "## 1. BluePrint Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0y6ix0d7m5q",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BluePrint dataset from HuggingFace\n",
    "# Available configurations: \"2_clusters\", \"100_clusters\", \"1000_clusters\"\n",
    "# Start with 100_clusters as a medium-sized dataset\n",
    "\n",
    "blueprint = load_dataset(\"ComplexDataLab/BluePrint\", \"100_clusters\")\n",
    "print(\"Dataset splits:\", blueprint.keys())\n",
    "print(\"\\nDataset info:\")\n",
    "print(blueprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cb74be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blueprint['full'].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lwm0qn8hkpd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas DataFrame\n",
    "df_blueprint = pd.DataFrame(blueprint['full'])\n",
    "print(f\"Shape: {df_blueprint.shape}\")\n",
    "print(f\"\\nColumns: {df_blueprint.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df_blueprint.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88yh8c6ne7w",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"Total samples: {len(df_blueprint):,}\")\n",
    "print(f\"\\nColumn info:\")\n",
    "print(df_blueprint.info())\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df_blueprint.isnull().sum())\n",
    "\n",
    "# Check cluster distribution\n",
    "print(f\"\\nNumber of unique clusters: {df_blueprint['cluster_id'].nunique()}\")\n",
    "print(f\"\\nCluster distribution (top 10):\")\n",
    "print(df_blueprint['cluster_id'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oo8q0bnjsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore thread structure\n",
    "print(\"Thread Structure Analysis:\")\n",
    "print(f\"\\nSample thread (first row):\")\n",
    "sample_thread = df_blueprint['thread'].iloc[0]\n",
    "print(type(sample_thread))\n",
    "print(f\"\\nThread length: {len(sample_thread) if isinstance(sample_thread, (list, dict)) else 'N/A'}\")\n",
    "print(f\"\\nThread content preview:\")\n",
    "print(sample_thread if not isinstance(sample_thread, list) or len(sample_thread) < 3 else sample_thread[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a8g7tthv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze thread lengths\n",
    "thread_lengths = df_blueprint['thread'].apply(lambda x: len(x) if isinstance(x, list) else 1)\n",
    "print(\"\\nThread Length Statistics:\")\n",
    "print(thread_lengths.describe())\n",
    "\n",
    "# Visualize cluster distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "cluster_counts = df_blueprint['cluster_id'].value_counts()\n",
    "plt.hist(cluster_counts, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Number of Threads per Cluster')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Threads Across Clusters')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(thread_lengths, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Thread Length (number of messages)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Thread Lengths')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y2qr6kjr71s",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep dive into thread content structure\n",
    "print(\"Detailed Thread Content Analysis:\")\n",
    "print(\"\\nExamining first thread in detail:\")\n",
    "first_thread = df_blueprint['thread'].iloc[0]\n",
    "\n",
    "if isinstance(first_thread, list) and len(first_thread) > 0:\n",
    "    print(f\"\\nNumber of messages in thread: {len(first_thread)}\")\n",
    "    print(f\"\\nFirst message structure:\")\n",
    "    print(type(first_thread[0]))\n",
    "    print(first_thread[0])\n",
    "    \n",
    "    # Check if messages have fields we need for moderation\n",
    "    if isinstance(first_thread[0], dict):\n",
    "        print(f\"\\nMessage fields: {first_thread[0].keys()}\")\n",
    "else:\n",
    "    print(f\"Thread type: {type(first_thread)}\")\n",
    "    print(f\"Thread content: {first_thread}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qd31as9p2o",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract key statistics about message content\n",
    "print(\"Message-Level Statistics:\")\n",
    "\n",
    "# Function to safely extract message fields\n",
    "def extract_message_info(thread):\n",
    "    if not isinstance(thread, list):\n",
    "        return None\n",
    "    \n",
    "    info = {\n",
    "        'num_messages': len(thread),\n",
    "        'unique_users': set(),\n",
    "        'has_text': False,\n",
    "        'has_actions': False\n",
    "    }\n",
    "    \n",
    "    for msg in thread:\n",
    "        if isinstance(msg, dict):\n",
    "            if 'user_id' in msg:\n",
    "                info['unique_users'].add(msg['user_id'])\n",
    "            if 'text' in msg or 'content' in msg:\n",
    "                info['has_text'] = True\n",
    "            if 'action' in msg or 'actions' in msg:\n",
    "                info['has_actions'] = True\n",
    "    \n",
    "    info['unique_users'] = len(info['unique_users'])\n",
    "    return info\n",
    "\n",
    "# Sample 1000 threads for analysis (to speed up)\n",
    "sample_size = min(1000, len(df_blueprint))\n",
    "sample_threads = df_blueprint['thread'].iloc[:sample_size]\n",
    "\n",
    "print(f\"\\nAnalyzing {sample_size} threads...\")\n",
    "thread_info = [extract_message_info(t) for t in sample_threads]\n",
    "thread_info = [t for t in thread_info if t is not None]\n",
    "\n",
    "if thread_info:\n",
    "    avg_messages = np.mean([t['num_messages'] for t in thread_info])\n",
    "    avg_users = np.mean([t['unique_users'] for t in thread_info])\n",
    "    print(f\"Average messages per thread: {avg_messages:.2f}\")\n",
    "    print(f\"Average unique users per thread: {avg_users:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zvzqgd8pex",
   "metadata": {},
   "source": [
    "## 2. Reddit Moderator Perceptions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "krz56oqgf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Reddit Moderator Perceptions dataset\n",
    "# Update with actual loading method based on dataset availability\n",
    "# Example: df_reddit = pd.read_csv('path_to_reddit_dataset.csv')\n",
    "# Or from GitHub: df_reddit = pd.read_json('https://...')\n",
    "\n",
    "# Placeholder - update with actual source\n",
    "print(\"Load Reddit Moderator Perceptions dataset here\")\n",
    "# df_reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6gk7qmdgvy7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics for Reddit dataset\n",
    "# print(f\"Shape: {df_reddit.shape}\")\n",
    "# print(f\"\\nColumns: {df_reddit.columns.tolist()}\")\n",
    "# print(f\"\\nMissing values:\")\n",
    "# print(df_reddit.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fidvd5ue8mi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore moderator perception categories\n",
    "# Analyze toxicity labels, enforcement actions, etc.\n",
    "# for col in categorical_cols:\n",
    "#     print(f\"\\n{col} distribution:\")\n",
    "#     print(df_reddit[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u6u3r8ni35",
   "metadata": {},
   "source": [
    "## 3. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ray95hcu45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of key findings\n",
    "print(\"=\"*60)\n",
    "print(\"KEY FINDINGS - BluePrint Dataset\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n1. DATASET SIZE:\")\n",
    "print(f\"   - Total threads: {len(df_blueprint):,}\")\n",
    "print(f\"   - Number of user clusters/personas: {df_blueprint['cluster_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\n2. DATA STRUCTURE:\")\n",
    "print(f\"   - Each row contains a conversation thread\")\n",
    "print(f\"   - Threads contain sequences of messages/interactions\")\n",
    "print(f\"   - Users grouped into {df_blueprint['cluster_id'].nunique()} behavioral personas\")\n",
    "\n",
    "print(f\"\\n3. RELEVANCE TO PROJECT:\")\n",
    "print(f\"   - Can identify different user archetypes from cluster_id\")\n",
    "print(f\"   - Thread structure allows modeling conversation dynamics\")\n",
    "print(f\"   - Suitable for training LLM agents on realistic interactions\")\n",
    "\n",
    "print(f\"\\n4. NEXT STEPS:\")\n",
    "print(f\"   - Map clusters to user archetypes (casual, influencer, toxic)\")\n",
    "print(f\"   - Extract and preprocess message content\")\n",
    "print(f\"   - Prepare training data for RLHF\")\n",
    "print(f\"   - Identify or annotate toxic/moderation-relevant content\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
